{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UTDataMining/2021A/blob/master/ex9/ex9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gcNG92z6Aaj"
      },
      "source": [
        "# 課題9 ロジスティック回帰\n",
        "\n",
        "配点\n",
        "- Q1 2\n",
        "- Q2 5\n",
        "- Q3 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7WiivOU6DKx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import  matplotlib.pyplot  as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUP5GXtj6S4g"
      },
      "source": [
        "# Colaboratoryでは以下を実行して必要なファイルをダウンロード\n",
        "!wget https://raw.githubusercontent.com/UTDataMining/2021S/master/ex8/iris.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5lTDaw-6bYA"
      },
      "source": [
        "irisデータセットの特徴量`petal_length`と`petal_width`で2つの花の種類`versicolor`か`virginica`のデータを散布図で可視化すると以下のように花ごとに`petal_length`と`petal_width`の特徴が異なることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XP3ORUe6aIP"
      },
      "source": [
        "iris = pd.read_csv('iris.csv')\n",
        "X=iris[(iris['species']=='versicolor')| (iris['species']=='virginica')][['petal_length', 'petal_width']].values\n",
        "y=iris[(iris['species']=='versicolor')| (iris['species']=='virginica')][['species']].values\n",
        "y = (y=='versicolor').astype(np.int) # versicolorを1、virginicaを0に\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.xlabel('petal_length')\n",
        "plt.ylabel('petal_width')\n",
        "plt.scatter(X[:,0], X[:,1], c=y[:,0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4zQ34Ea6h8p"
      },
      "source": [
        "以下では、ロジスティック回帰により特徴量`petal_length`と`petal_width`から2つの花の種類`versicolor`か`virginica`を予測するような仮説関数のパラメータを学習することを考えます。\n",
        "\n",
        "まず準備として、特徴量`petal_length`と`petal_width`を入力$X$, 花の種類`versicolor`か`virginica`を出力（ラベル）$y$とします。入力$X$は各特徴量ごとに標準化し、入力の各データにバイアス項($x_0=1$)を追加するため、入力の先頭列に1を要素とする列ベクトルを挿入します。これにより、入力$X$と出力$y$はデータ数を$m$としてそれぞれ行列（$m \\times 3$) とベクトル($m \\times 1$)になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClyU2WyL6fAv"
      },
      "source": [
        "X_norm=(X-np.mean(X, axis=0))/np.std(X, axis=0) # 標準化\n",
        "X_norm = np.hstack([np.ones((X.shape[0],1)), X_norm]) # バイアス項の追加"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcDrn9LX6nad"
      },
      "source": [
        "## Q1 シグモイド関数\n",
        "\n",
        "シグモイド関数$g(z)$は以下のように定義されます\n",
        "\n",
        "$g(z)=\\frac{1}{1+e^{-z}}$\n",
        "\n",
        "引数に`NumPy`の実数値を要素とする任意の長さの配列を入力として受け取り、配列の各要素に対するシグモイド関数の値を要素とする配列を返す`sigmoid`関数を完成させてください。\n",
        "\n",
        "[numpy.exp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFZYKmIf6mI_",
        "exercise_id": "q1",
        "inlinetests": {
          "InlineTest_1": "\nassert 'sigmoid' in globals(), f\"Have you defined the function 'sigmoid'?\"\nassert str(sigmoid.__class__) == \"<class 'function'>\", f\"Have you defined a function 'sigmoid'? Found a {sigmoid.__class__} instead\"\ntry:\n    assert np.round(sigmoid(np.array([-1.0,0.0,1.0])),2)[0] == 0.27, f\"Your function 'sigmoid' returns {sigmoid(np.array([-1.0,0.0,1.0]))}, while the expected answer is array([0.26..., 0.5, 0.73...])\"\n    assert np.round(sigmoid(np.array([-1.0,0.0,1.0])),2)[1] == 0.5, f\"Your function 'sigmoid' returns {sigmoid(np.array([-1.0,0.0,1.0]))}, while the expected answer is array([0.26..., 0.5, 0.73...])\"\n    assert np.round(sigmoid(np.array([-1.0,0.0,1.0])),2)[2] == 0.73, f\"Your function 'sigmoid' returns {sigmoid(np.array([-1.0,0.0,1.0]))}, while the expected answer is array([0.26..., 0.5, 0.73...])\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'sigmoid' does not accept 'Z' and raises an exception: {e}. Please try to pass `Z` to your function.\""
        }
      },
      "source": [
        "def sigmoid(Z):\n",
        "    Z = Z.astype(np.float) # float型にしておく\n",
        "    return ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvc5jY3R8N7a"
      },
      "source": [
        "`sigmoid`関数は入力の配列`[-1,0,1]`に対しては、配列`[0.26..., 0.5, 0.73...]`を返します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFOiZ7528VOH"
      },
      "source": [
        "sigmoid(np.array([-1,0,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ollemzWpA5Gn"
      },
      "source": [
        "## Q2 ロジスティック回帰のパラメータ推定\n",
        "\n",
        "以下では、最急降下法により、訓練データセットを元にロジスティック回帰の仮説関数のパラメータを学習する`graddes_logit`関数を実装します。\n",
        "\n",
        "`graddes_logit`関数では第1引数に入力のデータ行列（データ数($m$)$\\times$(特徴量+バイアス)($n$))、第2引数に入力の各データに対する出力（正解）のベクトル（$m\\times1$）、第3引数に学習率、第4引数に学習の繰り返し（各繰り返しをエポックと呼ぶ）の回数を受け取ります。\n",
        "\n",
        "これらの引数を元に、`graddes_logit`関数ではパラメータの学習を行い、以下を返します\n",
        "\n",
        "- エポックごとのコスト関数の値を要素とするリスト\n",
        "- 最終的なパラメータの値を要素とする配列（$n\\times1$）を返します。\n",
        "\n",
        "\n",
        "パラメータを$\\theta=(\\theta_0, \\theta_1, ..., \\theta_{n-1})^T$\n",
        "\n",
        "仮説関数を$h(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2+....+\\theta_{n-1}x_{n-1})=g(\\theta^Tx)=\\frac{1}{1+e^{-\\theta^Tx}}$\n",
        "\n",
        "入力を$\n",
        "  X = \\left(\n",
        "    \\begin{array}{cccc}\n",
        "      x_0^{(1)} &   x_1^{(1)} & ... &   x_{n-1}^{(1)}  \\\\\n",
        "      ... & ...& ...&...\\\\\n",
        "      x_0^{(m)} &  x_1^{(m)} & ... &   x_{n-1}^{(m)}  \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "$ \n",
        "\n",
        "$X$において$x_0^{(i)}=1$\n",
        "\n",
        "出力を$y=(y^{(1)}, y^{(2)}, ..., y^{(m)})^T$\n",
        "\n",
        "とすると、ロジスティック回帰のコスト関数を以下のようにして\n",
        "\n",
        "$J(\\theta)=-\\frac{1}{m}\\Sigma_{i=1}^{m}(y^{(i)}log(h(x^{(i)}))+(1-y^{(i)})log(1-h(x^{(i)})))$\n",
        "\n",
        "最急降下法では入力$X$の各特徴量$x_j$に対するパラメータ$\\theta_j$を以下の様に更新していきます。\n",
        "\n",
        "$\\theta_j:= \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} =  \\theta_j - \\frac{\\alpha}{m} \\Sigma_{i=1}^m ((h(x^{(i)})-y^{(i)})x^{(i)}_j)$\n",
        "\n",
        "パラメータ全体を以下のように一度に更新することもできます。\n",
        "\n",
        "$\\theta := \\theta - \\frac{\\alpha}{m}X^T(g(X\\theta)-y)$\n",
        "\n",
        "入力が1特徴量（変数）の時は、バイアス項に対するパラメータを$\\theta_0$、入力変数に対するパラメータを$\\theta_1$としてパラメータは以下の様に更新されます。\n",
        "\n",
        "$\\theta_0 := \\theta_0 - \\frac{\\alpha}{m}\\Sigma_{i=1}^m (h(x^{(i)})-y^{(i)})$ \n",
        "\n",
        "$\\theta_1 := \\theta_1 - \\frac{\\alpha}{m}\\Sigma_{i=1}^m ((h(x^{(i)})-y^{(i)})x^{(i)})$\n",
        "\n",
        "具体的に、`graddes_logit`関数では以下の手順によりパラメータの学習を行います。\n",
        "\n",
        "- 引数`n_iter`で指定されたエポックの回数だけ以下を繰り返す    \n",
        "\n",
        "     - すべてのm個のデータについて以下を求める\n",
        "        \n",
        "        - 入力データ$x^{(i)}$について仮説関数$h(x^{(i)})$の値を求める\n",
        "        \n",
        "        - 出力$y^{(i)}$との誤差$h(x^{(i)})-y^{(i)}$の値を求める\n",
        "    \n",
        " - すべてのm個のデータの誤差を用いてコスト関数$ J(\\theta)$の値を求め、各エポックのコスト関数の値を要素とするリスト`costs`に追加\n",
        " \n",
        " - すべてのm個のデータの誤差を用いて各パラメータ$\\theta_j (j=0,..,n-1)$を更新し、パラメータの値を要素とする配列`w`を更新\n",
        "      - `w[0,0]`$:=$($x_0$に対するパラメータ$\\theta_0$), \n",
        "      - ...,\n",
        "      - `w[n-1,0]`$:=$($x_{n-1}$に対するパラメータ$\\theta_{n-1}$)\n",
        "        \n",
        "\n",
        " \n",
        " すべての繰り返しが終了したらリスト`costs`と配列`w`を返す。\n",
        " \n",
        " 上記に従って、`graddes_logit`関数を完成させてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz8k7jY0A4la",
        "exercise_id": "q2",
        "inlinetests": {
          "InlineTest_2": "\nassert 'graddes_logit' in globals(), f\"Have you defined the function 'graddes_logit'?\"\nassert str(graddes_logit.__class__) == \"<class 'function'>\", f\"Have you defined a function 'graddes_logit'? Found a {graddes_logit.__class__} instead\"\ntry:\n    iris = pd.read_csv('iris.csv')\n    X=iris[(iris['species']=='versicolor')| (iris['species']=='virginica')][['petal_length', 'petal_width']].values\n    y=iris[(iris['species']=='versicolor')| (iris['species']=='virginica')][['species']].values\n    y = (y=='versicolor').astype(np.int)\n    costs, w = graddes_logit(np.hstack([np.ones((X.shape[0],1)), (X-np.mean(X, axis=0))/np.std(X, axis=0)]), y, 0.1, 100)\n    assert int(costs[-1]*1000) == 199, f\"Your function 'graddes_logit' with alpha:0.1 and n_iter:100 returns {costs[-1]}, while the expected answer is 0.199...\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'graddes_logit' does not accept 'X_norm, y' and raises an exception: {e}. Please try to pass `X_norm, y` to your function.\""
        }
      },
      "source": [
        "def graddes_logit(X, y, alpha, n_iter):  \n",
        "    m = X.shape[0] # データ数\n",
        "    n =  X.shape[1] # 次元（特徴量+バイアス）数\n",
        "    \n",
        "    costs=[] # エポックごとのコスト関数の値を入れるリスト\n",
        "    w = np.zeros((n,1)) #  バイアスと各特徴量に対するパラメータ（重み）の初期化\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "        ...\n",
        "    return costs, w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unuX8XfxCGhp"
      },
      "source": [
        "`graddes_logit`関数が完成したら以下のセルを実行して動作を確認してください。`graddes_logit`関数に訓練データセットを与え、学習率を0.1、学習のエポック数を100とした時の各エポックごとのコスト関数の値を示しています。パラメータの学習が進むにつれてコスト関数の値が減少していくことがわかります。この時の最終的なコスト関数の値は$\\simeq 0.199$となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hletTfZgCJbb"
      },
      "source": [
        "a=0.1 # 学習率\n",
        "n=100 # 繰り返し回数\n",
        "costs, w = graddes_logit(X_norm, y, a, n)\n",
        "print(costs[-1])\n",
        "print(w)\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(range(1,n+1),costs) # 繰り返しとコスト関数のプロット\n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('Iteration');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJGJKnzODzjk"
      },
      "source": [
        "学習されたパラメータを元に、2つの特徴量、`petal_length`と`petal_width`、から2つの花の種類、`versicolor`か`virginica`、を分類するための決定境界を可視化してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-dg2SF8D2Bj"
      },
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "x1=np.arange(X_norm[:,1].min(),X_norm[:,1].max(),0.1)\n",
        "plt.plot(x1, -(w[1,0]*x1+w[0,0])/w[2,0])\n",
        "plt.xlabel('petal_length')\n",
        "plt.ylabel('petal_width')\n",
        "plt.scatter(X_norm[:,1], X_norm[:,2],c=y[:,0]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUS50EcMD-Ed"
      },
      "source": [
        "2つの特徴量、`petal_length`($x_1$)と`petal_width`($x_2$)に対する、仮説関数$y=\\frac{1}{1+e^{-(\\theta_0+\\theta_1x_1+\\theta_2x_2)}}$（ロジスティック関数）は以下のようになります。以下の曲面で$y=0.5$となるところが上記の決定境界になっています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRmZtB0xD7vM"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "X1, X2 = np.meshgrid(np.arange(-2.0, 2.0, 0.1), np.arange(-2.0, 2.0, 0.1))\n",
        "Z = sigmoid(w[0,0]+w[1,0]*X1+ w[2,0]*X2)\n",
        "\n",
        "fig = plt.figure(figsize=(10,7))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.set_xlabel(\"petal_length\")\n",
        "ax.set_ylabel(\"petal_widht\")\n",
        "ax.plot_wireframe(X1, X2, Z);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOEZ0P0nEReh"
      },
      "source": [
        "## Q3 分類の評価\n",
        "以下では、タイタニック号の乗船者のデータを含むCSVファイル `'titanic.csv'` を `pandas` モジュールのデータフレームオブジェクトとしてロードし、乗船者の特徴量 （`Pclass`（客室の等級） と `Fare`（運賃）と`Age`（年齢）と`Sex`（性別）） からラベル `Survived` で表される乗客が生存したか（生存は`1`、非生存は`0`）を予測するモデルをロジスティック回帰を用いて学習します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nlkIg_UEYgM"
      },
      "source": [
        "# Colaboratoryでは以下を実行して必要なファイルをダウンロード\n",
        "!wget https://raw.githubusercontent.com/UTDataMining/2021S/master/ex9/titanic.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05y67MUEcHr"
      },
      "source": [
        "df = pd.read_csv('titanic.csv')\n",
        "df[['Pclass','Fare','Age','Sex','Survived']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1yyU2iLFWFa"
      },
      "source": [
        "性別の特徴量をラベルエンコーディングします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afagpbV3Eg_L"
      },
      "source": [
        "df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "df[['Pclass','Fare','Age','Sex','Survived']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqksclPpFhgT"
      },
      "source": [
        "Q2で作成した関数を用いてロジスティック回帰モデルのパラメータを推定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhOB9R24FOmz"
      },
      "source": [
        "X = df[['Pclass','Fare','Age','Sex']].values\n",
        "y = df[['Survived']].values\n",
        "\n",
        "X_norm=(X-np.mean(X, axis=0))/np.std(X, axis=0) # 標準化\n",
        "X_norm=np.insert(X_norm, 0, np.ones((1,X.shape[0]), dtype=int), axis=1) # バイアス項の追加\n",
        "\n",
        "a=0.1 # 学習率\n",
        "n=500 # 繰り返し回数\n",
        "costs, w = graddes_logit(X_norm, y, a, n)\n",
        "\n",
        "print(costs[-1]) # 最終的なコストの値\n",
        "print(w) # パラメータ\n",
        "\n",
        "# 繰り返しとコスト関数のプロット\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(range(1,n+1),costs) \n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('Iteration');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SIqUfC4Fx9x"
      },
      "source": [
        "実際のラベルの値を含む配列`y`(shapeは(データ数,1)の列ベクトル）と予測されたラベルの値を含む配列`y_pred`(`y`と同様のshape）をそれぞれ第1引数、第2引数に受け取り、それらを元に（accuracy, precision, recall, f値）を計算して返す以下の`evaluation`関数を完成させてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19_CxqQSDzuS",
        "exercise_id": "q3",
        "inlinetests": {
          "InlineTest_3": "\nassert 'evaluation' in globals(), f\"Have you defined the function 'evaluation'?\"\nassert str(evaluation.__class__) == \"<class 'function'>\", f\"Have you defined a function 'evaluation'? Found a {evaluation.__class__} instead\"\ntry:\n    df = pd.read_csv('titanic.csv')\n    df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n    X = df[['Pclass','Fare','Age','Sex']].values\n    y = df[['Survived']].values\n    X = np.hstack([np.ones((X.shape[0],1)), (X-np.mean(X, axis=0))/np.std(X, axis=0)])\n    costs, w = graddes_logit(X, y, 0.1, 500)\n    y_pred = (1.0/(1.0+np.exp(-np.dot(X,w)))>=0.5).astype(np.int)  \n    assert np.round(evaluation(y,y_pred),2)[0] == 0.80, f\"Your function 'sigmoid' returns {evaluation(y,y_pred)}, while the expected answer is (0.80..., 0.75..., 0.71..., 0.73...)\"\n    assert np.round(evaluation(y,y_pred),2)[1] == 0.76, f\"Your function 'sigmoid' returns {evaluation(y,y_pred)}, while the expected answer is (0.80..., 0.75..., 0.71..., 0.73...)\"\n    assert np.round(evaluation(y,y_pred),2)[2] == 0.72, f\"Your function 'sigmoid' returns {evaluation(y,y_pred)}, while the expected answer is (0.80..., 0.75..., 0.71..., 0.73...)\"\n    assert np.round(evaluation(y,y_pred),2)[3] == 0.74, f\"Your function 'sigmoid' returns {evaluation(y,y_pred)}, while the expected answer is (0.80..., 0.75..., 0.71..., 0.73...)\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'evaluation' does not accept 'y, y_pred' and raises an exception: {e}. Please try to pass 'y, y_pred' to your function.\""
        }
      },
      "source": [
        "def evaluation(y, y_pred):\n",
        "    accuracy = ...\n",
        "    precision = ...\n",
        "    recall = ...\n",
        "    f1 = ...\n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4ETU0ItHLKA"
      },
      "source": [
        "`evaluation`関数が完成したら以下のセルを実行して動作を確認してください。\n",
        "\n",
        "生存のクラス（ラベルは1）に関するaccuracyは`0.80...`、precisionは`0.75...`、recallは`0.71...`、f値は`0.73...`となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1N1ZRPYFRI_"
      },
      "source": [
        "output = sigmoid(np.dot(X_norm, w))\n",
        "y_pred = (output>=0.5).astype(np.int) \n",
        "evaluation(y, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnsffE6pHla1"
      },
      "source": [
        "scikit-learnの関数で各評価値を計算すると以下のようになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBhFlECj__D_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix,  precision_score, recall_score, f1_score\n",
        "\n",
        "print(confusion_matrix(y, y_pred)) # 混同行列\n",
        "print(accuracy_score(y, y_pred)) # accuracy\n",
        "print(precision_score(y, y_pred)) # precision\n",
        "print(recall_score(y, y_pred)) # recall\n",
        "print(f1_score(y, y_pred))  # f値"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fi3cCOc7vut"
      },
      "source": [
        "## コードのテスト\n",
        "以下の実行ボタンを押してから、設問ごとにCheck関数でコードのテストをしてください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZYlzknb7uLP"
      },
      "source": [
        "## コードのテストの前にこのセルを実行してください\n",
        "!pip install prog_edu_assistant_tools\n",
        "import re\n",
        "import sys\n",
        "import jinja2\n",
        "from IPython.core import display\n",
        "from google.colab import _message as google_message\n",
        "from prog_edu_assistant_tools.magics import report, autotest, CaptureOutput\n",
        "from prog_edu_assistant_tools.check import Check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC7vzQl4759e"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTSEQYzw748m"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlzUEX9r7-MK"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJGRw8u-7_FF"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmvOPRwD8BIR"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hiA5AZT8CsW"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q3')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}