{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UTDataMining/2022A/blob/main/ex8/ex8_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkEFgYv75zaQ"
      },
      "source": [
        "# EX8 Linear Regression\n",
        "\n",
        "Points\n",
        "- Q1 1\n",
        "- Q2 1\n",
        "- Q3 5\n",
        "- Q4 3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWLJ_bE95oSu"
      },
      "source": [
        "# モジュールのインポート\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFB5ZpGs6o4x"
      },
      "source": [
        "# Colaboratoryでは以下を実行して必要なファイルをダウンロード\n",
        "!wget https://raw.githubusercontent.com/UTDataMining/2022A/master/ex8/iris.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nGcCRWZ7JIS"
      },
      "source": [
        "## Q1 Correlation coefficient\n",
        "The following scatterplot shows the relationship between `petal_length` and `petal_width` features of the iris dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqIzexNi7Rf6",
        "outputId": "51816464-f195-4c82-8541-bd3d90341b98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "iris = pd.read_csv('iris.csv')\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.xlabel('petal_length')\n",
        "plt.ylabel('petal_width')\n",
        "plt.scatter(iris['petal_length'], iris['petal_width'], c='blue');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5_UZRRa7aLk"
      },
      "source": [
        "Complete the following `petal_corr` function that takes `petal_length` and `petal_width` features of the iris dataset, as `NumPy` arrays, with the arguments `x` and `y` respectively, and returns their correlation coefficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdwMKy8S7mht",
        "exercise_id": "q1",
        "inlinetests": {
          "InlineTest_1": "\nassert 'petal_corr' in globals(), f\"Have you defined the function 'petal_corr'?\"\nassert str(petal_corr.__class__) == \"<class 'function'>\", f\"Have you defined a function 'peta_corr'? Found a {petal_corr.__class__} instead\"\ntry:\n    iris = pd.read_csv('iris.csv')\n    X = iris[['petal_length']].values\n    y = iris[['petal_width']].values\n    assert int(petal_corr(X, y)*100) == 96, f\"Your function 'petal_corr' returns {petal_corr(X, y)}, while the expected answer is 0.96...\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'petal_corr' does not accept 'X, y' and raises an exception: {e}. Please try to pass `X, y` to your function.\""
        }
      },
      "source": [
        "def petal_corr(x,y):\n",
        "    return ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99WbGNIP7tnG"
      },
      "source": [
        "Once the `petal_corr` function is complete, run the following cell. Your function should return $\\simeq0.96$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7-nexX7wyy"
      },
      "source": [
        "X=iris[['petal_length']].values # 入力X\n",
        "y=iris[['petal_width']].values # 出力y\n",
        "\n",
        "petal_corr(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm8MEOBi8cOp"
      },
      "source": [
        "## Q2 Normalization\n",
        "\n",
        "In the following, let us consider learning the parameters of our hypothetical function to predict `petal_width` from `petal_length` using linear regression.\n",
        "\n",
        "First, as a preparation, consider normalizing both `petal_length` (as input $X$) and `petal_length` (as output $y$).\n",
        "\n",
        "Complete the following `normalizer` function that takes a `NumPy` 2D array of any number of rows and columns with the argument `mat` and returns an array with each element value normalized based on the mean and standard deviation of its column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-bXOcTw8icv",
        "exercise_id": "q2",
        "inlinetests": {
          "InlineTest_2": "\nassert 'normalizer' in globals(), f\"Have you defined the function 'normalizer'?\"\nassert str(normalizer.__class__) == \"<class 'function'>\", f\"Have you defined a function 'normalizer'? Found a {normalizer.__class__} instead\"\ntry:\n    iris = pd.read_csv('iris.csv')\n    X = iris[['petal_length']].values\n    assert np.round(np.mean(normalizer(X), axis=0))[0] == 0, f\"Your function 'normalizer' returns {np.round(np.mean(normalizer(X), axis=0))[0]}, while the expected answer is 0\"\n    assert np.round(np.std(normalizer(X), axis=0))[0] == 1, f\"Your function 'normalizer' returns {np.round(np.std(normalizer(X), axis=0))[0]}, while the expected answer is 1\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'normalizer' does not accept 'X' and raises an exception: {e}. Please try to pass `X` to your function.\""
        }
      },
      "source": [
        "def normalizer(mat):\n",
        "    return ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjkIuXWV8rn8"
      },
      "source": [
        "Once the `normalizer` function is complete, run the following cell. \n",
        "Make sure that each column of `X` column (in this case, checking its 1st column) is normalized to mean 0 and standard deviation 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBZ-DSjC9HoA"
      },
      "source": [
        "print(np.round(np.mean(normalizer(X), axis=0))[0])\n",
        "print(np.round(np.std(normalizer(X), axis=0))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMKhguvvATaH"
      },
      "source": [
        "In the following, we add a bias term ($x_0=1$) by inserting a column vector with elements of 1 in the first column of `X`. As a result, we now have the following matrix ($m \\times 2$) and vector ($m \\times 1$) for our input and output data respectively.\n",
        "\n",
        "$\n",
        "  X = \\left(\n",
        "    \\begin{array}{cc}\n",
        "      1 &   x^{(1)} \\\\\n",
        "      1 &   x^{(2)}  \\\\\n",
        "      ... & ... \\\\\n",
        "      1 &  x^{(m)}\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "$\n",
        "\n",
        "($x^{(i)}$: normalized `petal_length`)\n",
        "\n",
        "$\n",
        "  y = \\left(\n",
        "    \\begin{array}{c}\n",
        "       y^{(1)}  \\\\\n",
        "      ...\\\\\n",
        "        y^{(m)}  \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "$\n",
        "\n",
        "($y^{(i)}$: normalized `petal_width`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agj8sycbAhQW"
      },
      "source": [
        "X_norm = normalizer(X) # 入力の標準化\n",
        "y_norm = normalizer(y) # 出力の標準化\n",
        "\n",
        "X_norm = np.hstack([np.ones((X.shape[0],1)), X_norm]) # バイアス項の追加\n",
        "\n",
        "print(X_norm[:10,:]) # 先頭10行のデータ\n",
        "print(y_norm[:10]) # 先頭10行のデータ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTz2zF0lCISE"
      },
      "source": [
        "## Q3 Gradient descent\n",
        "In the following, we implement the `graddes` function that learns the parameters of a hypothetical function using the gradient descent method. The `graddes` function is trained based on the training data so that it can predict the output from the input.\n",
        "\n",
        "The `graddes` function takes the input data (number of data ($m$)$\\times$(number of features + bias)($n$)), the output data ($m\\times1$), the learning rate, and the number of training iterations (each iteration is called an epoch) with the arguments `X`, `y`, `alpha`, and `n_iter` respectively.\n",
        "\n",
        "The `graddes` function learns the parameters and then returns:\n",
        "- A list consisting of the costs of each iteration\n",
        "- An array of the parameters ($n\\times1$)\n",
        "\n",
        "#### Model training\n",
        "Let parameters be\n",
        "\n",
        "$\\theta=(\\theta_0, \\theta_1, ..., \\theta_{n-1})^T$,\n",
        "\n",
        "a hypothetical function (model) be\n",
        "\n",
        "$h(x)=\\theta_0+\\theta_1x_1+\\theta_2x_2+....+\\theta_{n-1}x_{n-1}$,\n",
        "\n",
        "an input be\n",
        "\n",
        "$\n",
        "  X = \\left(\n",
        "    \\begin{array}{cccc}\n",
        "      x_0^{(1)} &   x_1^{(1)} & ... &   x_{n-1}^{(1)}  \\\\\n",
        "      ... & ...& ...&...\\\\\n",
        "      x_0^{(m)} &  x_1^{(m)} & ... &   x_{n-1}^{(m)}  \\\\\n",
        "    \\end{array}\n",
        "  \\right)\n",
        "$\n",
        "\n",
        "(where $x_0^{(i)}=1$),\n",
        "\n",
        "and an output be\n",
        "\n",
        "$y=(y^{(1)}, y^{(2)}, ..., y^{(m)})^T$.\n",
        "\n",
        "Given the following cost function\n",
        "\n",
        "$J(\\theta)=\\frac{1}{2m}\\Sigma_{i=1}^m (h(x^{(i)})-y^{(i)})^2$,\n",
        "\n",
        "we update the parameter $\\theta_j$ corresponding the feature $x_j$ of $X$ using the gradient descent method as follows:\n",
        "\n",
        "$\\theta_j:= \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j} =  \\theta_j - \\frac{\\alpha}{m} \\Sigma_{i=1}^m ((h(x^{(i)})-y^{(i)})x^{(i)}_j)$\n",
        "\n",
        "The entire parameters can also be updated at once as follows:\n",
        "\n",
        "$\\theta := \\theta - \\frac{\\alpha}{m}X^T(X\\theta-y)$\n",
        "\n",
        "When we have one feature as the input, the parameters are updated as follows:\n",
        "\n",
        "$\\theta_0 := \\theta_0 - \\alpha  \\Sigma_{i=1}^m (h(x^{(i)})-y^{(i)})/m$ \n",
        "\n",
        "(the parameter for a bias term)\n",
        "\n",
        "$\\theta_1 := \\theta_1 - \\alpha  \\Sigma_{i=1}^m ((h(x^{(i)})-y^{(i)})x^{(i)})/m$\n",
        "\n",
        "(the parameter for the input feature)\n",
        "\n",
        "The `graddes` function learns the parameters according to the following procedure.\n",
        "\n",
        "- Repeat the following procedure `n_iter` times    \n",
        "     - For all m data\n",
        "        - Calculate the output of the hypothesis function $h(x^{(i)})$ for $x^{(i)}$.  \n",
        "        - Calculate the error $h(x^{(i)})-y^{(i)}$ with $y^{(i)}$.\n",
        "     - Calculate the cost $J(\\theta)$ using the errors of all m data and append it to `costs`.\n",
        "     - Update `w` with the parameters $\\theta_j(j=0,. ,n-1)$ using the errors of all m data,\n",
        "          - `w[0,0]`$:=$(parameter $\\theta_0$ for $x_0$), \n",
        "          - ... ,\n",
        "          - `w[n-1,0]`$:=$(parameter $\\theta_{n-1}$ for $x_{n-1}$)\n",
        "\n",
        "\n",
        "Return `costs` and `w` after all the iterations have been completed.\n",
        " \n",
        "Complete the `graddes` function according to the above procedure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CODrz_-jCTMy",
        "exercise_id": "q3",
        "inlinetests": {
          "InlineTest_3": "\nassert 'graddes' in globals(), f\"Have you defined the function 'graddes'?\"\nassert str(graddes.__class__) == \"<class 'function'>\", f\"Have you defined a function 'graddes'? Found a {graddes.__class__} instead\"\ntry:\n    iris = pd.read_csv('iris.csv')\n    X = iris[['petal_length']].values\n    y = iris[['petal_width']].values\n    costs, w = graddes(np.hstack([np.ones((X.shape[0],1)), normalizer(X)]), normalizer(y), 0.05, 20)\n    assert int(costs[-1]*1000) == 102, f\"Your function 'graddes' with alpha:0.05 and n_iter:20 returns {costs[-1]}, while the expected answer is 0.102...\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'graddes' does not accept 'X_norm, y_norm' and raises an exception: {e}. Please try to pass `X_norm, y_norm` to your function.\""
        }
      },
      "source": [
        "def graddes(X, y, alpha, n_iter):  \n",
        "    m = X.shape[0] # データ数\n",
        "    n = X.shape[1] # 次元（特徴量+バイアス）数\n",
        "    \n",
        "    costs = [] # エポックごとのコスト関数の値を入れるリスト\n",
        "    w = np.zeros((n,1)) #  各特徴量に対するパラメータ（重み）の初期化\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "        ...\n",
        "        \n",
        "    return costs, w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR6kWIGhCe3s"
      },
      "source": [
        "Once the `graddes` is complete, run the following cell. Your function should return the cost $\\simeq 0.102$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asoim3WsCi1W"
      },
      "source": [
        "n_iter=20\n",
        "alpha=0.05\n",
        "costs, w = graddes(X_norm, y_norm, alpha, n_iter)\n",
        "print(costs[-1]) # 100エポックでのコスト関数の値\n",
        "print(w) # 推定されたパラメータ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS1ovSX0Crrj"
      },
      "source": [
        "The following plot shows the relationship between each epoch and its cost. The cost value decreases as the learning process progresses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7vrGqc2ED_N"
      },
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('Iteration');\n",
        "plt.plot(range(1,n_iter+1),costs);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKObG1IdEG8W"
      },
      "source": [
        "The following plot shows $y=\\theta_0+\\theta_1x$ with `petal_length` as input $x$ and `petal_length` as output $y$ using the learned parameters $\\theta_0, \\theta_1$ (learning rate 0.05 and the number of iterations 20).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwTrzHgNEKyF"
      },
      "source": [
        "# 回帰直線のプロット\n",
        "def lineplot(X,y,w):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.xlabel('petal_length')\n",
        "    plt.ylabel('petal_width')\n",
        "    plt.scatter(X[:,1],y[:,0],c='blue')\n",
        "    plt.plot(X[:,1], np.dot(X,w)[:,0], color='red');\n",
        "\n",
        "lineplot(X_norm, y_norm, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVpintSSEQ3n"
      },
      "source": [
        "The following cell visualizes the cost function $J(\\theta)$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwS5ghEEVnN"
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# コスト関数のプロット\n",
        "def costplot(X, y, w, cost):\n",
        "    w0, w1 = np.meshgrid(np.arange(-3.0, 3.0, 0.1), np.arange(-3.0, 3.0, 0.1))\n",
        "    J=np.zeros(w0.shape)\n",
        "    for i in range(w0.shape[0]):\n",
        "        for j in range(w0.shape[1]):\n",
        "            J[i,j] = np.sum((np.dot(X, np.array([[w0[i,j]],[w1[i,j]]]))-y)**2)/(2*X.shape[0])\n",
        "    fig = plt.figure(figsize=(10,7))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "    ax.set_xlabel(\"theta0\")\n",
        "    ax.set_ylabel(\"theta1\")\n",
        "    ax.scatter(w[0,0], w[1,0], cost, s=100, c='red')\n",
        "    ax.plot_wireframe(w0, w1, J);\n",
        "\n",
        "costplot(X_norm, y_norm, w, costs[-1] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxNuU-FBEZ28"
      },
      "source": [
        "Change the learning rate $\\alpha$ and the number of iterations and observe the parameters and cost.\n",
        "\n",
        "Make sure that the cost has converged sufficiently and visualise the regression line using the learned parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn6pHtMJEdO-"
      },
      "source": [
        "n_iter = ... #エポック数\n",
        "alpha = ... #学習率\n",
        "costs, w = graddes(X_norm, y_norm, alpha, n_iter)\n",
        "print(costs[-1]) # コスト関数の値\n",
        "print(w) # 推定されたパラメータ\n",
        "\n",
        "# エポック数 vs. コスト関数\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('Iteration');\n",
        "plt.plot(range(1,n_iter+1),costs);\n",
        "\n",
        "# 回帰直線\n",
        "lineplot(X_norm, y_norm, w)\n",
        "\n",
        "# コスト関数\n",
        "costplot(X_norm, y_norm, w, costs[-1] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6y_4lo1GNrF"
      },
      "source": [
        "## Q4 Normal equation\n",
        "The parameters of linear regression can be obtained analytically by solving the following normal equation for $X$ and $y$ (assuming $X^TX$ is full rank)\n",
        "\n",
        "$\\theta = (X^TX)^{-1}X^Ty$\n",
        "\n",
        "where the transpose $A^T$ and inverse $A^{-1}$ of matrix $A$ can be calculated using `NumPy` as follows.\n",
        "\n",
        "Transpose $A^T$\n",
        "```Python\n",
        "A.T\n",
        "```\n",
        "\n",
        "Inverse $A^{-1}$\n",
        "```Python\n",
        "np.linalg.inv(A)\n",
        "```\n",
        "\n",
        "Complete the `normal_equation` function that takes the input data (number of data ($m$)$\\times$ of dimensions ($n$)) and the output data ($m\\times1$) with the arguments `X` and `y` respectively and return the parameters $\\theta$ ($n\\times1$) (similar in format to `w` of parameters in Q3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WneaefNGWea",
        "exercise_id": "q4",
        "inlinetests": {
          "InlineTest_4": "\nassert 'normal_equation' in globals(), f\"Have you defined the function 'normal_equation'?\"\nassert str(normal_equation.__class__) == \"<class 'function'>\", f\"Have you defined a function 'normal_equation'? Found a {normal_equation.__class__} instead\"\ntry:\n    iris = pd.read_csv('iris.csv')\n    X = iris[['petal_length']].values\n    y = iris[['petal_width']].values\n    w = normal_equation(np.hstack([np.ones((X.shape[0],1)), normalizer(X)]), normalizer(y))\n    assert np.round(w, 2)[0,0] == 0, f\"Your function 'normal_equation' returns {w[0,0]}, while the expected answer is about 0\"\n    assert np.round(w, 2)[1,0] == 0.96, f\"Your function 'normal_equation' returns {w[0,1]}, while the expected answer is about 0.96...\"\nexcept AssertionError as e:\n    raise e\nexcept Exception as e:\n    assert False, f\"Your function 'normal_equation' does not accept 'X_norm, y_norm' and raises an exception: {e}. Please try to pass `X_norm, y_norm` to your function.\""
        }
      },
      "source": [
        "def normal_equation(X, y):\n",
        "    return ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHWUNGptGXQ4"
      },
      "source": [
        "Once the `normal_equation` function is complete, run the following cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWjV2evbGb3p"
      },
      "source": [
        "w=normal_equation(X_norm, y_norm)\n",
        "print(w)\n",
        "\n",
        "lineplot(X_norm, y_norm, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PjAQMkS59nH"
      },
      "source": [
        "## Code Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU6U7Kdb55gT"
      },
      "source": [
        "## Run this cell first\n",
        "!pip install prog_edu_assistant_tools\n",
        "import re\n",
        "import sys\n",
        "import jinja2\n",
        "from IPython.core import display\n",
        "from google.colab import _message as google_message\n",
        "from prog_edu_assistant_tools.magics import report, autotest, CaptureOutput\n",
        "from prog_edu_assistant_tools.check import Check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2at-xYq6QRZ"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-xmfaIS6Opz"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IsdKOZc6Umc"
      },
      "source": [
        "## Q2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "674uMy0T6VfD"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MDfrXUP6XPa"
      },
      "source": [
        "## Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN2q5cE06YJi"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmI0KqMfJtQM"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG75NpGNJupV"
      },
      "source": [
        "# Run this cell to check your solution.\n",
        "# If you get an error 'Check not defined', make sure you have run all preceding\n",
        "# cells once (Runtime -> Run before)\n",
        "Check('q4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wPhSyeGJw8G"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}